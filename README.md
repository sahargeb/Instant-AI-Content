
Tasks:
1. How do you convert nonlinear to linear equations?
The standard form of a linear equation is Ax+By=C. To change an equation written in slope-intercept form (y=mx+b) to standard form, you must get the x and y on the same side of the equal sign and the constant on the other side. Use inverse operations to move terms.

2. What is PCA and how it works? 

Principal Component Analysis is primarily used for dimensionality reduction in domains like facial recognition, computer vision, image compression, and finding patterns in the field of finance, psychology, data mining, etc. PCA is used to extract the important information out of the dataset by combining the redundant features. These features are expressed in the form of new variables termed principal components. Since the visualization of the features in the dataset is limited, we can also use PCA to reduce the dimensionality of the dataset to 2 or 3 principal components and then visualize to get a better insight into it. PCA method is a part of the unsupervised machine learning technique. 
advantages of PCA:

1. It speeds up the learning algorithm.
2. Increases Efficiency due to lower dimensions.
3. It reduces the space required to store the data.
4. Data Visualization
5. Low sensitivity towards the noise.
6. Removes redundant variables


3. What are C++ Libraries / Frameworks for AI?
* TensorFlow
TensorFlow is a famous deep learning library created by Google with its environment of devices, libraries, community resources for machine learning. This library has a complete, adaptable environment of devices, libraries, and local area assets that lets analysts and engineers construct and convey ML-fueled applications without any problem. Regardless of whether you’re a specialist or an amateur, TensorFlow is an end-to-end platform that makes it easy for you to build and deploy ML models.
 
 Caffe from Berkeley
Convolutional architecture for fast feature embedding or Caffe is written in C++ for a deep learning structure, has been created by the Berkeley Vision and Learning Center. The provisions of this library incorporate expressive engineering, extensible code, speed, and a huge local area which fosters dynamic advancement in exploration and industry arrangements.
 
Microsoft Cognitive Toolkit (CNTK)
Written in C++, Microsoft Cognitive Toolkit is a brought-together deep learning tool stash that depicts neural networks as a progression of computational advances through a coordinated chart. It carries out stochastic inclination plunge (SGD, mistake backpropagation) learning with programmed separation and parallelization across various GPUs and servers. CNTK permits clients to effortlessly acknowledge and join famous model sorts like feed-forward DNNs, convolutional nets (CNNs), and recurrent networks (RNNs/LSTMs).
 
mlpack Library
mlpack is a fast, flexible machine learning library, written in C++. The library aims to provide fast, extensible implementations of cutting-edge machine learning algorithms. It also provides simple command-line programs, Python bindings, Julia bindings, and C++ classes which can be integrated into larger-scale machine learning solutions.
SHARK Library
Shark is a quick, particular, general open-source machine learning library (C/C++), for applications and examination, with help for direct and nonlinear advancement, portion-based learning calculations, neural organizations, and different other machine learning strategies.
Armadillo
Armadillo is a direct polynomial math (C/C++) library with functionality similar to Matlab. The library is renowned for the fast transformation of exploration code into creation conditions, for design acknowledgment, PC vision, signal handling, bioinformatics, insights, econometrics, among others.
Faisis
This library (C/C++) is used for efficient similarity search and clustering of dense vectors. It contains algorithms that search in sets of vectors of any size, up to ones that possibly do not fit in RAM. It also has support for optional GPU provided via CUDA, and an optional Python interface.
OpenNN
Written in C++, open neural networks (OpenNN) is an open-source neural networks library for advanced analytics. The library contains sophisticated algorithms and utilities to deal with the following artificial intelligence solutions such as classification, regression, forecasting, among others. The main advantage of this library is its high performance.
FANN
Fast artificial neural network (FANN) is an open-source neural network library written in C language. The library implements multilayer artificial neural networks in C with support for both fully connected and sparsely connected networks. It is easy to use, versatile, well documented, and fast. The features include backpropagation training, evolving topology training, cross-platform, and can use both floating-point and fixed-point numbers.
 
Boosting
XGBoost – A parallelized optimized general purpose gradient boosting library.
ThunderGBM – A fast library for GBDTs and Random Forests on GPUs.
LightGBM – Microsoft’s fast, distributed, high-performance gradient boosting (GBDT, GBRT, GBM, or MART) framework based on decision tree algorithms, used for ranking, classification, and many other machine learning tasks.
CatBoost – General purpose gradient boosting on decision trees library with categorical features support out of the box. It is easy to install, contains fast inference implementation, and supports CPU and GPU (even multi-GPU) computation.
 


 

